{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "495b3af9",
   "metadata": {},
   "source": [
    "## Summary of Learnings\n",
    "\n",
    "Through this task I gained not only technical practice but also conceptual clarity on several key ideas:\n",
    "\n",
    "* **Linear Regression for Classification:**\n",
    "  I learned that while Linear Regression can technically be adapted for binary classification by applying a threshold, it is not inherently suitable for this task. Its outputs are continuous and unbounded, which makes it less robust in distinguishing between two classes, especially in cases where the data overlap. This explained why its performance was weaker compared to Logistic Regression, which directly models class probabilities and is therefore better aligned with classification tasks. Working with Linear Regression in this context helped me understand its limitations and why specialized methods like Logistic Regression or SVM are preferable.\n",
    "\n",
    "* **Confusion Matrices:**\n",
    "  Confusion matrices turned out to be a very useful tool beyond accuracy. Accuracy only provides a single number, but confusion matrices break down predictions into **true positives, false positives, true negatives, and false negatives**. This breakdown showed me exactly where each classifier struggled. For example, some models tended to predict \"dog\" more often, leading to more false positives on cat images. This detailed view allowed me to compare not only overall performance but also the *type of mistakes* being made, which is crucial when applying models to real-world tasks where certain errors may be more costly than others.\n",
    "\n",
    "* **Learning Curves:**\n",
    "  Plotting and analyzing learning curves gave me insights into how each model behaved with increasing training data. Models like Decision Trees quickly reached high training accuracy but performed poorly on validation data, which highlighted overfitting. Random Forests and Logistic Regression had smoother, more stable learning curves, showing they generalized better. SVM consistently delivered strong results, though the gap between training and validation accuracy suggested there was still potential to tune parameters or add more training data. Learning curves taught me how to diagnose whether a model needs more data, better features, or regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84144a6f",
   "metadata": {},
   "source": [
    "### Overall Reflection\n",
    "\n",
    "This project showed me the practical strengths and weaknesses of classical machine learning models in image classification. I learned that:\n",
    "\n",
    "* Not every algorithm is equally suited for classification (e.g., Linear Regression is less effective).\n",
    "* Evaluation tools like confusion matrices and learning curves provide much deeper insights than accuracy alone.\n",
    "* Simple improvements such as adding extra classifiers (Logistic Regression, kNN, SVM, Voting) can substantially improve performance compared to the baseline.\n",
    "\n",
    "These lessons will be very useful for future projects, especially in understanding how to choose, evaluate, and improve models systematically."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
